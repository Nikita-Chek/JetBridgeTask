{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Finding out how much money McDonalds might be losing due to broken ice cream machines in the US\n",
    "\n",
    "### Aim\n",
    "Scripts will calculate the report daily and display the total amount lost in revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asamptions\n",
    "\n",
    "Note: All information and conclusions are based on assumptions from available sources.\n",
    "\n",
    "According to the official website of McDonaldâ€™s, it serves more than 25 million customers every day in the U.S in 14,000 restaurants (https://corporate.mcdonalds.com/corpmcd/en-us/our-stories/article/ourstories.adding-260000-jobs.html). So, there is about 1,785 visitors in each McDonalds per day.\n",
    "\n",
    "There is no relevant data on what percentage of customers order an ice cream, but in the same article it is mentioned that soft serve ice cream is used in more than 60% of its dessert menu. So, the assumption will be that about 50% of customers order a dessert of some description.\n",
    "\n",
    "That means 892 customers might order dessert in one restraint per day, 535 of them might order an ice cream. The average price of an ice cream vanilla cone is $1. Sundaes price is $1.29. McFlurry Small is $1.7, Medium $2.39 (https://cakesprices.com/mcdonalds-ice-cream/). Meaning that average price of an ice cream is $1.6. Therefore, the revenue per one McDonalds per day for ice creams is 856 \\$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting data from internet source and db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "URL = 'https://mcbroken2.nyc3.digitaloceanspaces.com/markers.json'\n",
    "\n",
    "\n",
    "async def get_data_from_url(URL: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get data from URL and return it as dict\n",
    "    Args:\n",
    "        URL (str): url of the resource\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the response status is not 200\n",
    "\n",
    "    Returns:\n",
    "        dict: Response data\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(URL) as resp:\n",
    "            if resp.status != 200:\n",
    "                raise Exception('API is not responding')\n",
    "            result = await resp.json()\n",
    "            return result\n",
    "\n",
    "\n",
    "async def get_processed_data() -> tuple[dict]:\n",
    "    \"\"\"\n",
    "    Process data from URL and return it as tuple of dicts.\n",
    "    Flatten the data, process the coordinates,\n",
    "    filter countries and active shops,\n",
    "    sort by coordinates\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict]: Tuple of dicts with processed data\n",
    "    \"\"\"\n",
    "    result = await get_data_from_url(URL)\n",
    "    result = result['features']\n",
    "    for i, value in enumerate(result):\n",
    "        result[i] = value['properties'] | value['geometry']\n",
    "        result[i]['coordinates'] = tuple(\n",
    "            float(coord) for coord in result[i]['coordinates']\n",
    "        )\n",
    "    result = filter(\n",
    "        lambda row:\n",
    "            row['country'] == 'USA' and\n",
    "            row['is_active'] == True,\n",
    "        result)\n",
    "    result = sorted(result, key=lambda row: row['coordinates'])\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "async def get_processed_data_db(data_collection) -> tuple[dict]:\n",
    "    \"\"\"\n",
    "    Get data from database and return it as tuple of dicts.\n",
    "    Transforms coordinates from list to tuple of floats.\n",
    "\n",
    "    Args:\n",
    "        data_collection: mongo database collection\n",
    "\n",
    "    Returns:\n",
    "        tuple[dict]: processed data\n",
    "    \"\"\"\n",
    "    cursor = data_collection.find({}).sort(\"datetime\", -1).limit(1)\n",
    "    old_data = await cursor.to_list(length=1)\n",
    "    if not old_data:\n",
    "        return tuple()\n",
    "    old_data = old_data[0]['data']\n",
    "    for i, value in enumerate(old_data):\n",
    "        old_data[i]['coordinates'] = tuple(\n",
    "            float(coord) for coord in value['coordinates']\n",
    "        )\n",
    "    return tuple(old_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_old = await get_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_new = await get_processed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare result by number of working machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare breakdowns in different periods, you can compare each point to each point.\n",
    "\n",
    "$n^2$\n",
    "\n",
    "But it is better to sort the two arrays, and go through them (taking into account that some points may have no similar ones in the other array). \n",
    "\n",
    "Sorting $ n\\ log(n) $ + while loop $ n $ = $n\\ log(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results_by_broken_index(new_data: list | tuple,\n",
    "                                    old_data: list | tuple) -> tuple[tuple]:\n",
    "    \"\"\"\n",
    "    Compare two lists of dictionaries by the index of the broken ice cream\n",
    "    machine. Results should be sorted by coordinates.\n",
    "\n",
    "    Args:\n",
    "        new_data (list | tuple): Sorted by coordinates list of new results\n",
    "        old_data (list | tuple): Sorted by coordinates list of old results\n",
    "\n",
    "    Returns:\n",
    "        tuple[tuple]: (\n",
    "            mcdonalds with fixed ice cream machines,\n",
    "            mcdonalds with broken ice cream machines\n",
    "            )\n",
    "    \"\"\"\n",
    "    old_len, new_len = len(old_data), len(new_data)\n",
    "    i, j = 0, 0\n",
    "    started_working, stoped_working = [], []\n",
    "    while (i < new_len) and (j < old_len):\n",
    "        if new_data[i]['coordinates'] == old_data[j]['coordinates']:\n",
    "            if new_data[i]['is_broken'] and (not old_data[j]['is_broken']):\n",
    "                stoped_working.append(new_data[i])\n",
    "            if (not new_data[i]['is_broken']) and old_data[j]['is_broken']:\n",
    "                started_working.append(new_data[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif new_data[i]['coordinates'] > old_data[j]['coordinates']:\n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return tuple(started_working), tuple(stoped_working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results_by_broken_index(result_new, result_old);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make daily reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "RESTAURANT_CLIENTS_PER_DAY = 1785\n",
    "DISERT_ORDER_PERSENT = 0.5\n",
    "ICE_CREAM_ORDER_PERSENT = 0.6\n",
    "ICE_CREAM_PRICE = 1.6\n",
    "ICE_CREAM_REVENUE_PER_DAY = (\n",
    "    RESTAURANT_CLIENTS_PER_DAY *\n",
    "    DISERT_ORDER_PERSENT *\n",
    "    ICE_CREAM_ORDER_PERSENT *\n",
    "    ICE_CREAM_PRICE\n",
    ")\n",
    "\n",
    "\n",
    "def make_report(new_data: tuple,\n",
    "                old_data: tuple) -> dict:\n",
    "    \"\"\"\n",
    "    Makes report by compare new and old data,\n",
    "    evaluate revenue and broken ice cream machines\n",
    "\n",
    "    Args:\n",
    "        new_data (tuple): new data\n",
    "        old_data (tuple): old data\n",
    "\n",
    "    Returns:\n",
    "        dict: report\n",
    "    \"\"\"\n",
    "    broken_machines = sum(map(lambda row: row['is_broken'],\n",
    "                              new_data))\n",
    "    fixes, breakdowns = compare_results_by_broken_index(new_data, old_data)\n",
    "    report = {\n",
    "        \"datetime\": datetime.datetime.now(),\n",
    "        \"broken_machines\": broken_machines,\n",
    "        \"clients_count_per_day\": RESTAURANT_CLIENTS_PER_DAY,\n",
    "        \"currency\": \"USD\",\n",
    "        \"ice_cream_revenue_per_day\": ICE_CREAM_REVENUE_PER_DAY,\n",
    "        \"overall_losses\": broken_machines * ICE_CREAM_REVENUE_PER_DAY,\n",
    "        \"machine_fixed\": len(fixes),\n",
    "        \"machine_breakdown\": len(breakdowns),\n",
    "    }\n",
    "    return report, (fixes, breakdowns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, (_, _) = make_report(result_new, result_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "import os\n",
    "import motor\n",
    "from apscheduler.schedulers.asyncio import AsyncIOScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seting up db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    'mongodb://' +\n",
    "    os.environ['MONGODB_USERNAME'] + ':' +\n",
    "    os.environ['MONGODB_PASSWORD'] + '@' +\n",
    "    os.environ['MONGODB_HOSTNAME'] + ':27017/')\n",
    "client = motor.motor_asyncio.AsyncIOMotorClient(connection_string)\n",
    "db = client.scrapperdb\n",
    "report_collection = db.reports\n",
    "data_collection = db.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define daily Task Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes data from sources, if there is no data in the database, then it initializes. Otherwise, there is a comparison of the previous day and the current day.\n",
    "\n",
    "For simplicity, for now, I just output the results to the console. For more serious implementations, you can use for example Airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def daily_task():\n",
    "    old_data = await get_processed_data_db(data_collection)\n",
    "    new_data = await get_processed_data()\n",
    "    document = {\n",
    "        \"datetime\": datetime.now(),\n",
    "        \"data\": new_data\n",
    "    }\n",
    "    result = await data_collection.insert_one(document)\n",
    "\n",
    "    if not old_data:\n",
    "        print(\"Initial load\")\n",
    "        return\n",
    "\n",
    "    report, (fixes, breakdowns) = make_report(new_data, old_data)\n",
    "    await report_collection.insert_one(report)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running main file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a minute, not a day, for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main(scheduler: AsyncIOScheduler):\n",
    "    try:\n",
    "        scheduler.start()\n",
    "        while True:\n",
    "            await asyncio.sleep(1)\n",
    "    except:\n",
    "        scheduler.shutdown()\n",
    "        print('Scheduler stopped')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scheduler = AsyncIOScheduler()\n",
    "    scheduler.add_job(daily_task, 'interval', seconds=60)\n",
    "    try:\n",
    "        asyncio.run(main(scheduler))\n",
    "    except KeyboardInterrupt:\n",
    "        print('Bye!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the records in the database, through <b>mongosh</b>.\n",
    "\n",
    "<img src=\"pict\\Screenshot 2022-09-25 193056.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or via docker-compose console.log\n",
    "\n",
    "<img src=\"pict\\Screenshot 2022-09-25 193601.png\" width=1000 height=60 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1917f08aa6f95a98b7b2cabe78d639649fe7c8ad680f16a7b021713d35db533e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
